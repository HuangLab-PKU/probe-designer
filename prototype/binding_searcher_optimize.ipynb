{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probe Designer\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basci env\n",
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "import json\n",
    "\n",
    "# data process of file from ncbi\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio.SeqUtils import MeltingTemp as mt\n",
    "\n",
    "# get gene data from ncbi\n",
    "from Bio import Entrez\n",
    "\n",
    "# blast and xml file process\n",
    "from Bio.Blast import NCBIWWW\n",
    "from Bio.Blast import NCBIXML\n",
    "\n",
    "\n",
    "# dir\n",
    "os.chdir(\"/home/akikawa/repos/probe_designer/dataset/2023.10.24_ChunhongZheng_pancreatic_cancer copy\")\n",
    "current_time = time.localtime()\n",
    "formatted_time = time.strftime(\"%Y%m%d_%H%M%S\", current_time)\n",
    "tmp = \"./results/\" + formatted_time + \"/tmp/\"\n",
    "output = \"./results/\" + formatted_time + \"/\"\n",
    "# tmp = './results/' + '20231026_203549' + '/tmp/'\n",
    "# output = './results/' + '20231026_203549' + '/'\n",
    "pre_binding_dir = tmp + \"pre_binding/\"\n",
    "try:\n",
    "    os.makedirs(tmp)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# basic variables\n",
    "gene_name_list_tosearch = \"gene_name_list_tosearch.txt\"\n",
    "pre_binding_file_suffix = \"_pre_binding.fasta\"\n",
    "total_pre_binding_file_name = \"_total_pre_binding.fasta\"\n",
    "\n",
    "# tmp file\n",
    "gene_name_list_file = \"1_gene_name_list.txt\"\n",
    "gene_id_name_file = \"2_id_list.txt\"\n",
    "gene_seq_in_file = \"3_gene_seq_in_file.gb\"\n",
    "pre_binding_num_file = \"4_pre_binding_num.json\"\n",
    "blast_results_file = \"5_blast_results.xml\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get genbank file of each gene from ncbi dataset\n",
    "\n",
    "https://www.ncbi.nlm.nih.gov/books/NBK25499/#chapter4.EFetch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get gene id and other information from ncbi dataset(api)\n",
    "## Generate gene_search_list from gene_name_list\n",
    "organism_of_interest = \"Homo sapiens\"\n",
    "n_type_of_interest = \"mRNA\"\n",
    "with open(tmp + gene_name_list_file) as f:\n",
    "    gene_name_list = f.read().splitlines()\n",
    "gene_search_list = [\n",
    "    \", \".join([name, organism_of_interest, n_type_of_interest])\n",
    "    for name in gene_name_list\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get gene id list using Entrez.esearch\n",
    "id_list = []\n",
    "for gene_search in gene_search_list:\n",
    "    Entrez.email = \"1418767067@qq.com\"\n",
    "    handle = Entrez.esearch(db=\"nuccore\", term=gene_search)\n",
    "    record = Entrez.read(handle)\n",
    "    handle.close()\n",
    "    id_list += record[\"IdList\"][:1]  # set number of search results to read\n",
    "with open(tmp + gene_id_name_file, \"w\") as f:\n",
    "    f.write(\"\\n\".join(id_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read id_list from existing file\n",
    "with open(tmp + gene_id_name_file, \"r\") as f:\n",
    "    id_list = f.read().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 100.0 %\n"
     ]
    }
   ],
   "source": [
    "# Get the genbank file of each gene by search for id list\n",
    "fetch_per_round = 3\n",
    "round = -(-len(id_list) // fetch_per_round)\n",
    "\n",
    "# initialization of gb file\n",
    "with open(tmp + gene_seq_in_file, \"w\") as f:\n",
    "    f.write(\"\")\n",
    "\n",
    "for i in range(round):\n",
    "    id_list_per_round = id_list[i * fetch_per_round : (i + 1) * fetch_per_round]\n",
    "    Entrez.email = \"1418767067@qq.com\"\n",
    "    handle = Entrez.efetch(\n",
    "        db=\"nuccore\",\n",
    "        strand=1,  # plus if strand=1\n",
    "        id=id_list_per_round,\n",
    "        rettype=\"gbwithparts\",\n",
    "        retmode=\"text\",\n",
    "    )\n",
    "    seq_record = handle.read()\n",
    "    handle.close()\n",
    "    print(i + 1, \"{:.1f} %\".format((i + 1) / round * 100))\n",
    "    with open(tmp + gene_seq_in_file, \"a\") as f:\n",
    "        f.write(seq_record)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binding site Searcher\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def select_random_non_overlapping_substrings(input_string, length, num_substrings):\n",
    "    if length > len(input_string) or num_substrings * length > len(input_string):\n",
    "        # if length > len(input_string):\n",
    "        raise ValueError(\"Invalid input parameters.\")\n",
    "\n",
    "    available_positions = list(range(len(input_string) - length + 1))\n",
    "    random.shuffle(available_positions)\n",
    "\n",
    "    substrings = []\n",
    "    positions = set()  # To keep track of selected positions\n",
    "\n",
    "    for _ in range(num_substrings):\n",
    "        if not available_positions:\n",
    "            break  # Stop if there are no more non-overlapping positions\n",
    "\n",
    "        # Try to find a non-overlapping position\n",
    "        selected_position = available_positions.pop()\n",
    "        while selected_position in positions:\n",
    "            if not available_positions:\n",
    "                break\n",
    "            selected_position = available_positions.pop()\n",
    "\n",
    "        if selected_position not in positions:\n",
    "            positions.add(selected_position)\n",
    "            end = selected_position + length\n",
    "            selected_substring = input_string[selected_position:end]\n",
    "            substrings.append(selected_substring)\n",
    "\n",
    "    return substrings\n",
    "\n",
    "\n",
    "def find_max_min_difference_fixed_length_subsequence(\n",
    "    arr,\n",
    "    length,\n",
    "    min_gap,\n",
    "    better_gap=80,\n",
    "    gene=\"\",\n",
    "):\n",
    "    arr.sort()  # 对输入列表进行排序\n",
    "\n",
    "    def is_valid(min_difference, length, min_gap):\n",
    "        count = 1\n",
    "        current_min = arr[0]\n",
    "\n",
    "        for i in range(1, len(arr)):\n",
    "            if arr[i] - current_min >= min_difference:\n",
    "                count += 1\n",
    "                current_min = arr[i]\n",
    "\n",
    "        return count >= length and min_difference > min_gap\n",
    "\n",
    "    left, right = 0, arr[-1] - arr[0]\n",
    "    result = []\n",
    "    while left <= right:\n",
    "        mid = (left + right) // 2\n",
    "        if is_valid(mid, length, min_gap):\n",
    "            result = [arr[0]]\n",
    "            current_min = arr[0]\n",
    "            for i in range(1, len(arr)):\n",
    "                if arr[i] - current_min >= mid:\n",
    "                    result.append(arr[i])\n",
    "                    current_min = arr[i]\n",
    "            left = mid + 1\n",
    "        else:\n",
    "            right = mid - 1\n",
    "\n",
    "    if result == []:\n",
    "        print(f\"Gene {gene}: \\tNot enough pos for {length} binding sites.\")\n",
    "        result = arr\n",
    "\n",
    "    if mid < better_gap:\n",
    "        print(f\"Gene {gene}: \\tcondition too harsh, loose to get better results\")\n",
    "        print(result)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def step_by_step(\n",
    "    sequence,\n",
    "    BDS_len,\n",
    "    BDS_num,\n",
    "    min_gap,\n",
    "    better_gap,\n",
    "    gene=\"\",\n",
    "    G_min=0.3,\n",
    "    G_max=0.7,\n",
    "    G_consecutive=5,\n",
    "    Tm_low=50,\n",
    "    Tm_high=65,\n",
    "    pin_gap=0.1,\n",
    "):\n",
    "    seq_gap = int(len(sequence) * pin_gap)\n",
    "    sequence = sequence[seq_gap : len(sequence) - seq_gap]\n",
    "    position = [_ for _ in range(len(sequence) - BDS_len)]\n",
    "    pos_of_True = []\n",
    "    Tm_l_list = [0] * len(position)\n",
    "    Tm_r_list = [0] * len(position)\n",
    "    for pos in tqdm(position, desc=f\"position_searching_{gene}\"):\n",
    "        bds = sequence[pos : pos + BDS_len]\n",
    "        # check G 40%-70%, non consective 5 base\n",
    "        if \"G\" * G_consecutive in bds:\n",
    "            continue\n",
    "        G_per = bds.count(\"G\") / len(bds)\n",
    "        if G_per < G_min or G_per > G_max:\n",
    "            continue\n",
    "        # check Tm\n",
    "        Tm_l = mt.Tm_NN(bds[: BDS_len // 2], nn_table=mt.R_DNA_NN1)\n",
    "        Tm_r = mt.Tm_NN(bds[BDS_len // 2 :], nn_table=mt.R_DNA_NN1)\n",
    "        if Tm_l > Tm_high or Tm_l < Tm_low or Tm_r > Tm_high or Tm_r < Tm_low:\n",
    "            continue\n",
    "        pos_of_True.append(pos)\n",
    "        Tm_l_list[pos] = Tm_l\n",
    "        Tm_r_list[pos] = Tm_r\n",
    "\n",
    "    best_pos = find_max_min_difference_fixed_length_subsequence(\n",
    "        pos_of_True,\n",
    "        BDS_num,\n",
    "        min_gap=min_gap,\n",
    "        better_gap=better_gap,\n",
    "        gene=gene,\n",
    "    )\n",
    "    Tm_l = [Tm_l_list[_] for _ in best_pos]\n",
    "    Tm_r = [Tm_r_list[_] for _ in best_pos]\n",
    "    seq_out = [sequence[_ : _ + BDS_len] for _ in best_pos]\n",
    "\n",
    "    return (\n",
    "        Tm_l,\n",
    "        Tm_r,\n",
    "        seq_out,\n",
    "        [_ + seq_gap for _ in best_pos],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "position_searching_CTRB1: 100%|██████████| 656/656 [00:00<00:00, 11751.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "condition for gene CTRB1 too harsh, loose to get better results\n",
      "[2, 12, 21, 33, 42, 51, 67, 119, 129, 138, 151, 160, 173, 185, 194, 214, 234, 243, 252, 265, 274, 285, 294, 303, 313, 323, 333, 342, 353, 362, 371, 422, 433, 442, 451, 460, 484, 499, 508, 519, 528, 537, 546, 555, 566, 575, 586, 595, 604, 623, 639, 648]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Initiation of array\n",
    "binding_site_FOIs = [\n",
    "    \"accession\",\n",
    "    \"gene_name\",\n",
    "    \"mol_type\",\n",
    "    \"organism\",\n",
    "    \"pos_on_seq\",\n",
    "    \"binding\",\n",
    "    \"Tm_l\",\n",
    "    \"Tm_r\",\n",
    "    \"wanted\",\n",
    "]\n",
    "align_FOIs = [\"align_num\", \"align_accession\", \"align_descrip\", \"plus/minus\"]\n",
    "FOI = pd.DataFrame(columns=binding_site_FOIs + align_FOIs)\n",
    "\n",
    "# Search binding sites on mRNA sequence\n",
    "file_in = tmp + gene_seq_in_file\n",
    "file_out_dir = pre_binding_dir\n",
    "try:\n",
    "    os.mkdir(file_out_dir)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "pre_binding_num = {}\n",
    "\n",
    "# initialization of file\n",
    "with open(file_out_dir + total_pre_binding_file_name, \"w\") as handle:\n",
    "    handle.write(\"\")\n",
    "\n",
    "for gene_seq_gb in SeqIO.parse(tmp + gene_seq_in_file, \"genbank\"):\n",
    "    # get information of gene\n",
    "    id = gene_seq_gb.id  # get seq id\n",
    "\n",
    "    # get gene_name\n",
    "    if gene_seq_gb.features:\n",
    "        for feature in gene_seq_gb.features:\n",
    "            if feature.type == \"CDS\":\n",
    "                gene_name = feature.qualifiers.get(\"gene\", [\"NAN\"])[0]\n",
    "\n",
    "    # get molecule_type\n",
    "    mol_type = gene_seq_gb.annotations[\"molecule_type\"]\n",
    "\n",
    "    # get organism\n",
    "    organism = gene_seq_gb.annotations[\"organism\"]\n",
    "\n",
    "    # get minus seq\n",
    "    translib = {\"A\": \"T\", \"T\": \"A\", \"C\": \"G\", \"G\": \"C\"}\n",
    "    try:\n",
    "        seq_minus = [translib[i] for i in str(gene_seq_gb.seq)]\n",
    "        seq = \"\".join(list(reversed(seq_minus)))\n",
    "    except:\n",
    "        seq = str(gene_seq_gb.seq)\n",
    "\n",
    "    record_list = []\n",
    "    file_out = file_out_dir + gene_name + pre_binding_file_suffix\n",
    "\n",
    "    Tm_l, Tm_r, selected_substrings, pos_on_seq = step_by_step(\n",
    "        seq,\n",
    "        BDS_len=40,\n",
    "        BDS_num=50,\n",
    "        min_gap=1,\n",
    "        better_gap=40,\n",
    "        gene=gene_name,\n",
    "        G_min=0.25,\n",
    "        G_max=0.7,\n",
    "        G_consecutive=5,\n",
    "        Tm_low=50,\n",
    "        Tm_high=65,\n",
    "    )\n",
    "\n",
    "    for i, pre_binding_tmp in enumerate(selected_substrings):\n",
    "        record_list.append(\n",
    "            SeqRecord(\n",
    "                Seq(pre_binding_tmp),\n",
    "                id=\"pre_binding\" + str(i),\n",
    "                description=\"|\".join([id, gene_name, organism, mol_type]),\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # add information about binding sites to FOI\n",
    "    add = pd.DataFrame(\n",
    "        {\n",
    "            \"accession\": [id] * len(selected_substrings),\n",
    "            \"gene_name\": [gene_name] * len(selected_substrings),\n",
    "            \"mol_type\": [mol_type] * len(selected_substrings),\n",
    "            \"organism\": [organism] * len(selected_substrings),\n",
    "            \"binding\": selected_substrings,\n",
    "            \"Tm_l\": Tm_l,\n",
    "            \"Tm_r\": Tm_r,\n",
    "            \"pos_on_seq\": pos_on_seq,\n",
    "        }\n",
    "    )\n",
    "    FOI = pd.concat([FOI, add], ignore_index=True)\n",
    "\n",
    "    # pos += pre_binding_num_tmp\n",
    "\n",
    "    # write pre_binding to files\n",
    "    with open(file_out, \"w\") as f:\n",
    "        for new_record in record_list:\n",
    "            SeqIO.write(new_record, f, \"fasta\")\n",
    "    with open(file_out_dir + total_pre_binding_file_name, \"a\") as handle:\n",
    "        for new_record in record_list:\n",
    "            SeqIO.write(new_record, handle, \"fasta\")\n",
    "\n",
    "    # record the num of pre_binding for each gene\n",
    "    # pre_binding_num[f\"{id}_{gene_name}\"] = pre_binding_num_tmp\n",
    "    pre_binding_num[f\"{id}_{gene_name}\"] = len(selected_substrings)\n",
    "\n",
    "with open(tmp + pre_binding_num_file, \"w\") as f:\n",
    "    json.dump(pre_binding_num, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blast and extract blast results\n",
    "\n",
    "NCBIXML: https://homolog.us/Biopython/Bio.Blast.NCBIXML.html#read/0\n",
    "\n",
    "BlastRecord: https://biopython.org/docs/1.75/api/Bio.Blast.Record.html\n",
    "\n",
    "XMLReader: https://codebeautify.org/xmlviewer#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file_out_dir + total_pre_binding_file_name, \"r\") as f:\n",
    "    fasta_string = f.read()\n",
    "txid = [2697049]  # organism\n",
    "\n",
    "# Submit BLAST search and get handle object\n",
    "handle = NCBIWWW.qblast(\n",
    "    program=\"blastn\",\n",
    "    megablast=\"yes\",\n",
    "    database=\"refseq_rna\",\n",
    "    sequence=fasta_string,\n",
    "    url_base=\"https://blast.ncbi.nlm.nih.gov/Blast.cgi\",\n",
    "    format_object=\"Alignment\",\n",
    "    format_type=\"Xml\",\n",
    ")\n",
    "\n",
    "# read handle object and save to a file\n",
    "with open(tmp + blast_results_file, \"w\") as f:\n",
    "    f.write(handle.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract interested information from blast_results\n",
    "align_num = []\n",
    "\n",
    "# read the id/plus-minus part/align_num\n",
    "with open(tmp + blast_results_file, \"r\") as blast_output:\n",
    "    blast_records = NCBIXML.parse(blast_output)\n",
    "    loca = 0\n",
    "    for blast_record in blast_records:\n",
    "        align_accession = []\n",
    "        align_descrip_list = []\n",
    "        # get align num of each binding site\n",
    "        length = len(blast_record.alignments)\n",
    "        align_num.append(length)\n",
    "        for i in range(length):\n",
    "            descrip = blast_record.descriptions[i].title.split(\"|\")\n",
    "            # get accession and descrip of each align seq\n",
    "            align_accession.append(descrip[3])\n",
    "            align_descrip_list.append(descrip[-1])\n",
    "        FOI.loc[loca, \"align_accession\"] = \"|\".join(str(_) for _ in align_accession)\n",
    "\n",
    "        # add align_descrip to df\n",
    "        FOI.loc[loca, \"align_descrip\"] = \"|\".join(str(_) for _ in align_descrip_list)\n",
    "\n",
    "        # get plus/minus of each align seq\n",
    "        p_m = [blast_record.alignments[_].hsps[0].frame[1] for _ in range(length)]\n",
    "\n",
    "        # add plus/minus to df\n",
    "        try:\n",
    "            FOI.loc[loca, \"plus/minus\"] = \",\".join([str(_) for _ in p_m])\n",
    "        except:\n",
    "            FOI.loc[loca, \"plus/minus\"] = \"NAN\"\n",
    "\n",
    "        loca += 1\n",
    "\n",
    "FOI[\"align_num\"] = align_num"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select wanted binding site\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOI[\"wanted\"] = [True] * len(FOI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "condition for gene CTRB1 too harsh, loose to get better results\n",
      "[89, 99, 108, 120, 129]\n"
     ]
    }
   ],
   "source": [
    "# sieve for the suitable binding site\n",
    "gene_name_list = [_.upper() for _ in gene_name_list]\n",
    "gene_name_list_out = [i for i in gene_name_list]\n",
    "for i in range(len(FOI)):\n",
    "    # check gene_name\n",
    "    gene_name = FOI.loc[i, \"gene_name\"]\n",
    "    if gene_name.upper() not in gene_name_list:\n",
    "        FOI.loc[i, \"wanted\"] = False\n",
    "    else:\n",
    "        try:\n",
    "            gene_name_list_out.remove(gene_name)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    # check DNA or mRNA type\n",
    "    if FOI.loc[i, \"wanted\"] == True:\n",
    "        if FOI.loc[i, \"mol_type\"] != \"mRNA\":\n",
    "            FOI.loc[i, \"wanted\"] = False\n",
    "\n",
    "    # check gene_organism name\n",
    "    if FOI.loc[i, \"wanted\"] == True:\n",
    "        spe_ori, gene_ori = FOI.loc[i, \"organism\"], FOI.loc[i, \"gene_name\"]\n",
    "        descrip = FOI.loc[i, \"align_descrip\"].split(\"|\")\n",
    "        for des in descrip:\n",
    "            if gene_ori not in des and spe_ori in des:\n",
    "                FOI.loc[i, \"wanted\"] = False\n",
    "                break\n",
    "\n",
    "    # check plus/minus\n",
    "    if FOI.loc[i, \"wanted\"] == True:\n",
    "        if pd.isnull(FOI.loc[i, \"plus/minus\"]):\n",
    "            FOI.loc[i, \"wanted\"] = False\n",
    "        else:\n",
    "            pm_list = FOI.loc[i, \"plus/minus\"].split(\",\")\n",
    "            if \"-1\" not in pm_list:\n",
    "                FOI.loc[i, \"wanted\"] = False\n",
    "\n",
    "# write the whole information of interest to a excel file in tmp dir\n",
    "FOI.to_excel(tmp + \"probes_sieve.xlsx\")\n",
    "\n",
    "out_tmp = FOI[FOI[\"wanted\"] == True]\n",
    "output_df = pd.DataFrame()\n",
    "for gene in out_tmp.gene_name.unique():\n",
    "    pos_of_True = list(out_tmp[out_tmp.gene_name == gene][\"pos_on_seq\"])\n",
    "    best_pos = find_max_min_difference_fixed_length_subsequence(\n",
    "        pos_of_True,\n",
    "        length=3,\n",
    "        min_gap=40,\n",
    "        better_gap=80,\n",
    "        gene=gene,\n",
    "    )\n",
    "    out_subset = out_tmp[out_tmp.gene_name == gene]\n",
    "    out_subset = out_subset[out_subset[\"pos_on_seq\"].isin(best_pos)]\n",
    "    output_df = pd.concat([output_df, out_subset])\n",
    "\n",
    "# write the output to a xlsx file\n",
    "output_df.to_excel(output + \"probes_wanted.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
