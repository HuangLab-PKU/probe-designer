{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probe Designer\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basci env\n",
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "# data process of file from ncbi\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio.SeqUtils import MeltingTemp as mt\n",
    "\n",
    "# # get gene data from ncbi\n",
    "# from Bio import Entrez\n",
    "\n",
    "# # blast and xml file process\n",
    "from Bio.Blast import NCBIWWW\n",
    "from Bio.Blast import NCBIXML\n",
    "\n",
    "# add package to sys var\n",
    "# os.chdir(os.path.dirname(os.path.abspath(__file__)))\n",
    "# sys.path.append(\"../lib\")\n",
    "\n",
    "# dir\n",
    "workdir = './dataset/2024.3.27_mousebrain_HP_projection/'\n",
    "os.makedirs(workdir, exist_ok=True)\n",
    "\n",
    "current_time = time.localtime()\n",
    "formatted_time = time.strftime(\"%Y%m%d_%H%M%S\", current_time)\n",
    "\n",
    "output = os.path.join(workdir, 'results', formatted_time)\n",
    "pre_binding_dir = os.path.join(output, \"pre_binding\")\n",
    "os.makedirs(output, exist_ok=True)\n",
    "\n",
    "# basic variables\n",
    "gene_name_list_tosearch = \"gene_name_list_tosearch.txt\"\n",
    "pre_binding_file_suffix = \"_pre_binding.fasta\"\n",
    "total_pre_binding_file_name = \"_total.fasta\"\n",
    "\n",
    "# tmp file\n",
    "pre_binding_num_file = \"pre_binding_num.json\"\n",
    "blast_results_file = \"blast_results.xml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "organism = 'mouse'\n",
    "gene_info = pd.read_excel(os.path.join(workdir, \"Gene list_mouse.xlsx\"), sheet_name='Sheet1')\n",
    "gene_list = list(gene_info['gene_name'].unique())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get seq from ensembl dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from lib.database_interaction import ensembl_id_to_seqs\n",
    "# import time\n",
    "\n",
    "# skip = 0\n",
    "# trial = 0\n",
    "\n",
    "# tmp_isoform_list = isoform_list[skip:]\n",
    "# tmp_id_list = id_list[len(sequences_of_all)+skip:]\n",
    "\n",
    "# for i in range(len(tmp_isoform_list)):\n",
    "#     isoform = tmp_isoform_list[i]\n",
    "#     id = tmp_id_list[i]\n",
    "#     sequences_of_all[f'{id}_{isoform}'] = dict()\n",
    "#     sequences = ensembl_id_to_seqs(gene=isoform, gene_id=id.split('.')[0], seq_type='cds')\n",
    "#     for desc, sequence in sequences.items():\n",
    "#         sequences_of_all[f'{id}_{isoform}'][desc] = sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.database_interaction import ensembl_name_to_seqs\n",
    "import time\n",
    "\n",
    "\n",
    "max_trial = 3\n",
    "sequences_of_all = dict()\n",
    "error_messages = {gene: [] for gene in gene_list}\n",
    "\n",
    "with tqdm(total=len(gene_list), desc=\"total_process\", position=0) as pbar_total:\n",
    "    for gene in gene_list:\n",
    "        sequences_of_all[gene] = {}\n",
    "        trial_success = False\n",
    "        \n",
    "        # Reset the trial progress bar for each gene\n",
    "        for trial in range(1, max_trial+1):  # Retrying up to 3 times\n",
    "            try:\n",
    "                # Attempt to retrieve sequences\n",
    "                sequences_of_all[gene] = ensembl_name_to_seqs(gene=gene, species='mouse', seq_type='cds', tqdm_args={'position': 1,'leave': False})\n",
    "                trial_success = True\n",
    "                break\n",
    "            except Exception as e:\n",
    "                time.sleep(1)\n",
    "\n",
    "        if not trial_success:\n",
    "            error_messages[gene].append(f\"Failed to retrieve sequences for {gene} after {max_trial} attempts.:{e}\")\n",
    "\n",
    "        pbar_total.update(1)  # Update the main progress bar after each gene\n",
    "\n",
    "for gene, messages in error_messages.items():\n",
    "    for message in messages:\n",
    "        print(message)\n",
    "\n",
    "with open(os.path.join(output, 'sequence_of_all.json'), 'w') as file: json.dump(sequences_of_all, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(output, 'sequence_of_all.json'), 'r') as file: sequences_of_all = json.load(file)\n",
    "\n",
    "longest_isoforms = {}\n",
    "for gene, isoforms in sequences_of_all.items():\n",
    "    longest_isoform = None\n",
    "    max_length = 0\n",
    "    for isoform in isoforms:\n",
    "        if len(isoform['seq']) > max_length:\n",
    "            max_length = len(isoform['seq'])\n",
    "            longest_isoform = isoform\n",
    "    if longest_isoform:\n",
    "        longest_isoforms[gene] = longest_isoform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(output, 'longest_isoforms.json'), 'w') as file: json.dump(longest_isoforms, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "longest_isoform"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binding site Searcher\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.search_binding import step_by_step, find_max_min_difference_fixed_length_subsequence, seq_minus\n",
    "\n",
    "# Initiation of array\n",
    "binding_site_FOIs = [\n",
    "    \"accession\",\n",
    "    \"gene_name\",\n",
    "    \"mol_type\",\n",
    "    \"organism\",\n",
    "    \"pos_on_seq\",\n",
    "    \"binding\",\n",
    "    \"Tm_l\",\n",
    "    \"Tm_r\",\n",
    "    \"wanted\",\n",
    "]\n",
    "align_FOIs = [\"align_num\", \"align_accession\", \"align_descrip\", \"plus/minus\"]\n",
    "FOI = pd.DataFrame(columns=binding_site_FOIs + align_FOIs)\n",
    "\n",
    "# Search binding sites on mRNA sequence\n",
    "file_out_dir = pre_binding_dir\n",
    "try:\n",
    "    os.mkdir(file_out_dir)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "pre_binding_num = {}\n",
    "\n",
    "# initialization of file\n",
    "with open(os.path.join(file_out_dir, total_pre_binding_file_name), \"w\") as handle:\n",
    "    handle.write(\"\")\n",
    "\n",
    "for desc, info in longest_isoforms.items():\n",
    "    seq = info['seq']\n",
    "    id, gene_name, mol_type = info['id'], info['external_name'], info['biotype']\n",
    "    minus_seq = seq_minus(seq)\n",
    "    \n",
    "    Tm_l, Tm_r, selected_substrings, pos_on_seq = step_by_step(\n",
    "        minus_seq, gene=gene_name,\n",
    "        BDS_len=40, BDS_num=50, min_gap=1, better_gap=40,\n",
    "        G_min=0.25, G_max=0.7, G_consecutive=5, Tm_low=50, Tm_high=65)\n",
    "    \n",
    "    record_list = []\n",
    "    for i, pre_binding_tmp in enumerate(selected_substrings):\n",
    "        record_list.append(\n",
    "            SeqRecord(\n",
    "                Seq(pre_binding_tmp),\n",
    "                id=\"pre_binding\" + str(i),\n",
    "                description=\"|\".join([id, gene_name, organism, mol_type]),\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # add information about binding sites to FOI\n",
    "    add = pd.DataFrame(\n",
    "        {\n",
    "            \"accession\": [id] * len(selected_substrings),\n",
    "            \"gene_name\": [gene_name] * len(selected_substrings),\n",
    "            \"mol_type\": [mol_type] * len(selected_substrings),\n",
    "            \"organism\": [organism] * len(selected_substrings),\n",
    "            \"binding\": selected_substrings,\n",
    "            \"Tm_l\": Tm_l,\n",
    "            \"Tm_r\": Tm_r,\n",
    "            \"pos_on_seq\": pos_on_seq,\n",
    "        }\n",
    "    )\n",
    "    FOI = pd.concat([FOI, add], ignore_index=True)\n",
    "\n",
    "    file_out = os.path.join(file_out_dir, gene_name + pre_binding_file_suffix)\n",
    "    \n",
    "    # write pre_binding to files\n",
    "    with open(file_out, \"w\") as f:\n",
    "        for new_record in record_list:\n",
    "            SeqIO.write(new_record, f, \"fasta\")\n",
    "    with open(file_out_dir + total_pre_binding_file_name, \"a\") as handle:\n",
    "        for new_record in record_list:\n",
    "            SeqIO.write(new_record, handle, \"fasta\")\n",
    "\n",
    "    # record the num of pre_binding for each gene\n",
    "    pre_binding_num[f\"{id}_{gene_name}\"] = len(selected_substrings)\n",
    "\n",
    "with open(os.path.join(output, pre_binding_num_file), \"w\") as f:\n",
    "    json.dump(pre_binding_num, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blast and extract blast results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(file_out_dir + total_pre_binding_file_name, \"r\") as f:\n",
    "#     fasta_string = f.read()\n",
    "# txid = [2697049]  # organism\n",
    "\n",
    "# # Submit BLAST search and get handle object\n",
    "# handle = NCBIWWW.qblast(\n",
    "#     program=\"blastn\",\n",
    "#     megablast=\"yes\",\n",
    "#     database=\"refseq_rna\",\n",
    "#     sequence=fasta_string,\n",
    "#     url_base=\"https://blast.ncbi.nlm.nih.gov/Blast.cgi\",\n",
    "#     format_object=\"Alignment\",\n",
    "#     format_type=\"Xml\",\n",
    "# )\n",
    "\n",
    "# # read handle object and save to a file\n",
    "# with open(os.path.join(os.path.join(output, blast_results_file)), \"w\") as f:\n",
    "#     f.write(handle.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract interested information from blast_results\n",
    "from Bio.Blast import NCBIXML\n",
    "\n",
    "\n",
    "align_num = []\n",
    "# read the id/plus-minus part/align_num\n",
    "with open(os.path.join(output, blast_results_file), \"r\") as blast_output:\n",
    "    blast_records = NCBIXML.parse(blast_output)\n",
    "    loca = 0\n",
    "    for blast_record in blast_records:\n",
    "        align_accession = []\n",
    "        align_descrip_list = []\n",
    "        # get align num of each binding site\n",
    "        length = len(blast_record.alignments)\n",
    "        align_num.append(length)\n",
    "        for i in range(length):\n",
    "            descrip = blast_record.descriptions[i].title.split(\"|\")\n",
    "            # get accession and descrip of each align seq\n",
    "            align_accession.append(descrip[3])\n",
    "            align_descrip_list.append(descrip[-1])\n",
    "        FOI.loc[loca, \"align_accession\"] = \"|\".join(str(_) for _ in align_accession)\n",
    "\n",
    "        # add align_descrip to df\n",
    "        FOI.loc[loca, \"align_descrip\"] = \"|\".join(str(_) for _ in align_descrip_list)\n",
    "\n",
    "        # get plus/minus of each align seq\n",
    "        p_m = [blast_record.alignments[_].hsps[0].frame[1] for _ in range(length)]\n",
    "\n",
    "        # add plus/minus to df\n",
    "        try: FOI.loc[loca, \"plus/minus\"] = \",\".join([str(_) for _ in p_m])\n",
    "        except: FOI.loc[loca, \"plus/minus\"] = pd.NA\n",
    "\n",
    "        loca += 1\n",
    "\n",
    "FOI[\"align_num\"] = align_num"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select wanted binding site\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOI[\"wanted\"] = [True] * len(FOI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sieve for the suitable binding site\n",
    "gene_name_list = [_.upper() for _ in gene_list]\n",
    "gene_name_list_out = [i for i in gene_name_list]\n",
    "for i in range(len(FOI)):\n",
    "    # check gene_name\n",
    "    gene_name = FOI.loc[i, \"gene_name\"]\n",
    "    if gene_name.split('-')[0].upper() not in gene_name_list:\n",
    "        FOI.loc[i, \"wanted\"] = False\n",
    "    else:\n",
    "        try:\n",
    "            gene_name_list_out.remove(gene_name)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    # check DNA or mRNA type\n",
    "    if FOI.loc[i, \"wanted\"] == True:\n",
    "        if FOI.loc[i, \"mol_type\"] != \"protein_coding\":\n",
    "            FOI.loc[i, \"wanted\"] = False\n",
    "            print(FOI.loc[i, \"mol_type\"])\n",
    "\n",
    "    # check gene_organism name\n",
    "    if FOI.loc[i, \"wanted\"] == True:\n",
    "        spe_ori, gene_ori = FOI.loc[i, \"organism\"], FOI.loc[i, \"gene_name\"].split('-')[0]\n",
    "        descrip = FOI.loc[i, \"align_descrip\"].split(\"|\")\n",
    "        for des in descrip:\n",
    "            if gene_ori not in des and spe_ori in des:\n",
    "                FOI.loc[i, \"wanted\"] = False\n",
    "                break\n",
    "\n",
    "    # check plus/minus\n",
    "    if FOI.loc[i, \"wanted\"] == True:\n",
    "        if pd.isnull(FOI.loc[i, \"plus/minus\"]):\n",
    "            FOI.loc[i, \"wanted\"] = False\n",
    "        else:\n",
    "            pm_list = FOI.loc[i, \"plus/minus\"].split(\",\")\n",
    "            if \"-1\" not in pm_list:\n",
    "                FOI.loc[i, \"wanted\"] = False\n",
    "\n",
    "# write the whole information of interest to a excel file in tmp dir\n",
    "FOI.to_excel(os.path.join(output, \"probes_sieve.xlsx\"))\n",
    "\n",
    "out_tmp = FOI[FOI[\"wanted\"] == True]\n",
    "output_df = pd.DataFrame()\n",
    "for gene in out_tmp.gene_name.unique():\n",
    "    pos_of_True = list(out_tmp[out_tmp.gene_name == gene][\"pos_on_seq\"])\n",
    "    best_pos = find_max_min_difference_fixed_length_subsequence(\n",
    "        pos_of_True,\n",
    "        length=3,\n",
    "        min_gap=40,\n",
    "        better_gap=80,\n",
    "        gene=gene,\n",
    "    )\n",
    "    out_subset = out_tmp[out_tmp.gene_name == gene]\n",
    "    out_subset = out_subset[out_subset[\"pos_on_seq\"].isin(best_pos)]\n",
    "    output_df = pd.concat([output_df, out_subset])\n",
    "\n",
    "# write the output to a xlsx file\n",
    "output_df.to_excel(os.path.join(output, \"probes_wanted.xlsx\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
