{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probe Designer\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basci env\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import time\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "# data process of file from ncbi\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio.SeqUtils import MeltingTemp as mt\n",
    "\n",
    "# get gene data from ncbi\n",
    "from Bio import Entrez\n",
    "\n",
    "# blast and xml file process\n",
    "from Bio.Blast import NCBIWWW\n",
    "from Bio.Blast import NCBIXML\n",
    "\n",
    "# add package to sys var\n",
    "# os.chdir(os.path.dirname(os.path.abspath(__file__)))\n",
    "# sys.path.append(\"../lib\")\n",
    "\n",
    "# dir\n",
    "workdir = \"./dataset/2024.1.23_Sindy_marker_genes/\"\n",
    "os.makedirs(workdir, exist_ok=True)\n",
    "\n",
    "current_time = time.localtime()\n",
    "formatted_time = time.strftime(\"%Y%m%d_%H%M%S\", current_time)\n",
    "tmp = os.path.join(workdir, \"results\", formatted_time, \"tmp\")\n",
    "output = os.path.join(workdir, \"results\", formatted_time)\n",
    "pre_binding_dir = os.path.join(tmp, \"pre_binding\")\n",
    "os.makedirs(tmp, exist_ok=True)\n",
    "\n",
    "# basic variables\n",
    "gene_name_list_tosearch = \"gene_name_list_tosearch.txt\"\n",
    "pre_binding_file_suffix = \"_pre_binding.fasta\"\n",
    "total_pre_binding_file_name = \"_total_pre_binding.fasta\"\n",
    "\n",
    "# tmp file\n",
    "gene_name_list_file = \"gene_name_list.txt\"\n",
    "gene_id_name_file = \"gene_id_list.txt\"\n",
    "gene_seq_in_file = \"gene_seq_in_file.gb\"\n",
    "pre_binding_num_file = \"pre_binding_num.json\"\n",
    "blast_results_file = \"blast_results.xml\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get genbank file of each gene from ncbi dataset\n",
    "\n",
    "https://www.ncbi.nlm.nih.gov/books/NBK25499/#chapter4.EFetch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get gene id and other information from ncbi dataset(api)\n",
    "## Generate gene_search_list from gene_name_list\n",
    "organism_of_interest = \"Mus musculus\"\n",
    "n_type_of_interest = \"mRNA\"\n",
    "with open(os.path.join(tmp, gene_name_list_file)) as f: gene_name_list = f.read().splitlines()\n",
    "\n",
    "## Read id_list from existing file\n",
    "with open(os.path.join(tmp, gene_id_name_file), \"r\") as f: id_list = f.read().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Get gene id list using Entrez.esearch\n",
    "# gene_search_list = [\", \".join([name, organism_of_interest, n_type_of_interest])\n",
    "#     for name in gene_name_list]\n",
    "# id_list = []\n",
    "# for gene_search in gene_search_list:\n",
    "#     Entrez.email = \"1418767067@qq.com\"\n",
    "#     handle = Entrez.esearch(db=\"nuccore\", term=gene_search)\n",
    "#     record = Entrez.read(handle)\n",
    "#     handle.close()\n",
    "#     id_list += record[\"IdList\"][:1]  # set number of search results to read\n",
    "# with open(tmp + gene_id_name_file, \"w\") as f:\n",
    "#     f.write(\"\\n\".join(id_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.27s/it]\n"
     ]
    }
   ],
   "source": [
    "# Get the genbank file of each gene by id list\n",
    "fetch_per_round = 3\n",
    "round = -(-len(id_list) // fetch_per_round)\n",
    "\n",
    "# initialization of gb file\n",
    "with open(os.path.join(tmp, gene_seq_in_file), \"w\") as f:\n",
    "    f.write(\"\")\n",
    "\n",
    "for i in tqdm(range(round)):\n",
    "    id_list_per_round = id_list[i * fetch_per_round : (i + 1) * fetch_per_round]\n",
    "    Entrez.email = \"1418767067@qq.com\"\n",
    "    handle = Entrez.efetch(\n",
    "        db=\"nuccore\",\n",
    "        strand=1,  # plus if strand=1\n",
    "        id=id_list_per_round,\n",
    "        rettype=\"gbwithparts\",\n",
    "        retmode=\"text\",\n",
    "    )\n",
    "    seq_record = handle.read()\n",
    "    handle.close()\n",
    "    with open(os.path.join(tmp, gene_seq_in_file), \"a\") as f:\n",
    "        f.write(seq_record)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binding site Searcher\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "position_searching_Hexb: 100%|██████████| 1249/1249 [00:00<00:00, 44726.54it/s]\n",
      "C:\\Users\\Mingchuan\\AppData\\Local\\Temp\\ipykernel_19288\\265673762.py:71: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  FOI = pd.concat([FOI, add], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gene Hexb: \tcondition too harsh, loose to get better results\n",
      "[176, 179, 599, 602, 605, 608, 612, 632, 650, 653, 656, 660, 663, 666, 669, 672, 676, 1000, 1003, 1006, 1009, 1012, 1015, 1018, 1091, 1096, 1100, 1111, 1116, 1120, 1124, 1128, 1133, 1136, 1141, 1144, 1148, 1209, 1212, 1215, 1218, 1221, 1224, 1227, 1230, 1233, 1236, 1241, 1244, 1247]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "position_searching_Aqp4: 100%|██████████| 809/809 [00:00<00:00, 36871.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gene Aqp4: \tcondition too harsh, loose to get better results\n",
      "[65, 117, 122, 127, 133, 138, 144, 149, 154, 159, 206, 211, 257, 292, 459, 464, 474, 479, 484, 489, 503, 508, 513, 518, 523, 528, 533, 538, 543, 548, 553, 558, 606, 615, 621, 626, 631, 636, 641, 646, 651, 656, 661, 666, 671, 676, 681, 733, 738, 743, 748, 753, 758]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from lib.search_binding import step_by_step, find_max_min_difference_fixed_length_subsequence, gb_extract\n",
    "\n",
    "# Initiation of array\n",
    "binding_site_FOIs = [\n",
    "    \"accession\",\n",
    "    \"gene_name\",\n",
    "    \"mol_type\",\n",
    "    \"organism\",\n",
    "    \"pos_on_seq\",\n",
    "    \"binding\",\n",
    "    \"Tm_l\",\n",
    "    \"Tm_r\",\n",
    "    \"wanted\",\n",
    "]\n",
    "align_FOIs = [\"align_num\", \"align_accession\", \"align_descrip\", \"plus/minus\"]\n",
    "FOI = pd.DataFrame(columns=binding_site_FOIs + align_FOIs)\n",
    "\n",
    "# Search binding sites on mRNA sequence\n",
    "file_in = os.path.join(tmp, gene_seq_in_file)\n",
    "file_out_dir = pre_binding_dir\n",
    "try:\n",
    "    os.mkdir(file_out_dir)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "pre_binding_num = {}\n",
    "\n",
    "# initialization of file\n",
    "with open(os.path.join(file_out_dir, total_pre_binding_file_name), \"w\") as handle:\n",
    "    handle.write(\"\")\n",
    "\n",
    "for record in SeqIO.parse(os.path.join(tmp, gene_seq_in_file), \"genbank\"):\n",
    "    id, gene_name, mol_type, organism, minus_seq = gb_extract(record, CDS=True)\n",
    "    Tm_l, Tm_r, selected_substrings, pos_on_seq = step_by_step(\n",
    "        minus_seq,\n",
    "        BDS_len=40,\n",
    "        BDS_num=50,\n",
    "        min_gap=1,\n",
    "        better_gap=40,\n",
    "        gene=gene_name,\n",
    "        G_min=0.25,\n",
    "        G_max=0.7,\n",
    "        G_consecutive=5,\n",
    "        Tm_low=50,\n",
    "        Tm_high=65,\n",
    "    )\n",
    "    \n",
    "    record_list = []\n",
    "    for i, pre_binding_tmp in enumerate(selected_substrings):\n",
    "        record_list.append(\n",
    "            SeqRecord(\n",
    "                Seq(pre_binding_tmp),\n",
    "                id=\"pre_binding\" + str(i),\n",
    "                description=\"|\".join([id, gene_name, organism, mol_type]),\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # add information about binding sites to FOI\n",
    "    add = pd.DataFrame(\n",
    "        {\n",
    "            \"accession\": [id] * len(selected_substrings),\n",
    "            \"gene_name\": [gene_name] * len(selected_substrings),\n",
    "            \"mol_type\": [mol_type] * len(selected_substrings),\n",
    "            \"organism\": [organism] * len(selected_substrings),\n",
    "            \"binding\": selected_substrings,\n",
    "            \"Tm_l\": Tm_l,\n",
    "            \"Tm_r\": Tm_r,\n",
    "            \"pos_on_seq\": pos_on_seq,\n",
    "        }\n",
    "    )\n",
    "    FOI = pd.concat([FOI, add], ignore_index=True)\n",
    "\n",
    "    file_out = os.path.join(file_out_dir, gene_name + pre_binding_file_suffix)\n",
    "    \n",
    "    # write pre_binding to files\n",
    "    with open(file_out, \"w\") as f:\n",
    "        for new_record in record_list:\n",
    "            SeqIO.write(new_record, f, \"fasta\")\n",
    "    with open(os.path.join(file_out_dir, total_pre_binding_file_name), \"a\") as handle:\n",
    "        for new_record in record_list:\n",
    "            SeqIO.write(new_record, handle, \"fasta\")\n",
    "\n",
    "    # record the num of pre_binding for each gene\n",
    "    pre_binding_num[f\"{id}_{gene_name}\"] = len(selected_substrings)\n",
    "\n",
    "with open(os.path.join(tmp, pre_binding_num_file), \"w\") as f:\n",
    "    json.dump(pre_binding_num, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blast and extract blast results\n",
    "\n",
    "NCBIXML: https://homolog.us/Biopython/Bio.Blast.NCBIXML.html#read/0\n",
    "\n",
    "BlastRecord: https://biopython.org/docs/1.75/api/Bio.Blast.Record.html\n",
    "\n",
    "XMLReader: https://codebeautify.org/xmlviewer#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(file_out_dir + total_pre_binding_file_name, \"r\") as f:\n",
    "#     fasta_string = f.read()\n",
    "# txid = [2697049]  # organism\n",
    "\n",
    "# # Submit BLAST search and get handle object\n",
    "# handle = NCBIWWW.qblast(\n",
    "#     program=\"blastn\",\n",
    "#     megablast=\"yes\",\n",
    "#     database=\"refseq_rna\",\n",
    "#     sequence=fasta_string,\n",
    "#     url_base=\"https://blast.ncbi.nlm.nih.gov/Blast.cgi\",\n",
    "#     format_object=\"Alignment\",\n",
    "#     format_type=\"Xml\",\n",
    "# )\n",
    "\n",
    "# # read handle object and save to a file\n",
    "# with open(tmp + blast_results_file, \"w\") as f:\n",
    "#     f.write(handle.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract interested information from blast_results\n",
    "align_num = []\n",
    "\n",
    "# read the id/plus-minus part/align_num\n",
    "with open(os.path.join(tmp, blast_results_file), \"r\") as blast_output:\n",
    "    blast_records = NCBIXML.parse(blast_output)\n",
    "    loca = 0\n",
    "    for blast_record in blast_records:\n",
    "        align_accession = []\n",
    "        align_descrip_list = []\n",
    "        # get align num of each binding site\n",
    "        length = len(blast_record.alignments)\n",
    "        align_num.append(length)\n",
    "        for i in range(length):\n",
    "            descrip = blast_record.descriptions[i].title.split(\"|\")\n",
    "            # get accession and descrip of each align seq\n",
    "            align_accession.append(descrip[3])\n",
    "            align_descrip_list.append(descrip[-1])\n",
    "        FOI.loc[loca, \"align_accession\"] = \"|\".join(str(_) for _ in align_accession)\n",
    "\n",
    "        # add align_descrip to df\n",
    "        FOI.loc[loca, \"align_descrip\"] = \"|\".join(str(_) for _ in align_descrip_list)\n",
    "\n",
    "        # get plus/minus of each align seq\n",
    "        p_m = [blast_record.alignments[_].hsps[0].frame[1] for _ in range(length)]\n",
    "\n",
    "        # add plus/minus to df\n",
    "        try:\n",
    "            FOI.loc[loca, \"plus/minus\"] = \",\".join([str(_) for _ in p_m])\n",
    "        except:\n",
    "            FOI.loc[loca, \"plus/minus\"] = \"NAN\"\n",
    "\n",
    "        loca += 1\n",
    "\n",
    "FOI[\"align_num\"] = align_num"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select wanted binding site\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOI[\"wanted\"] = [True] * len(FOI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sieve for the suitable binding site\n",
    "gene_name_list = [_.upper() for _ in gene_name_list]\n",
    "gene_name_list_out = [i for i in gene_name_list]\n",
    "for i in range(len(FOI)):\n",
    "    # check gene_name\n",
    "    gene_name = FOI.loc[i, \"gene_name\"]\n",
    "    if gene_name.upper() not in gene_name_list:\n",
    "        FOI.loc[i, \"wanted\"] = False\n",
    "    else:\n",
    "        try:\n",
    "            gene_name_list_out.remove(gene_name)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    # check DNA or mRNA type\n",
    "    if FOI.loc[i, \"wanted\"] == True:\n",
    "        if FOI.loc[i, \"mol_type\"] != \"mRNA\":\n",
    "            FOI.loc[i, \"wanted\"] = False\n",
    "\n",
    "    # check gene_organism name\n",
    "    if FOI.loc[i, \"wanted\"] == True:\n",
    "        spe_ori, gene_ori = FOI.loc[i, \"organism\"], FOI.loc[i, \"gene_name\"]\n",
    "        descrip = FOI.loc[i, \"align_descrip\"].split(\"|\")\n",
    "        for des in descrip:\n",
    "            if gene_ori not in des and spe_ori in des:\n",
    "                FOI.loc[i, \"wanted\"] = False\n",
    "                break\n",
    "\n",
    "    # check plus/minus\n",
    "    if FOI.loc[i, \"wanted\"] == True:\n",
    "        if pd.isnull(FOI.loc[i, \"plus/minus\"]):\n",
    "            FOI.loc[i, \"wanted\"] = False\n",
    "        else:\n",
    "            pm_list = FOI.loc[i, \"plus/minus\"].split(\",\")\n",
    "            if \"-1\" not in pm_list:\n",
    "                FOI.loc[i, \"wanted\"] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the whole information of interest to a excel file in tmp dir\n",
    "FOI.to_excel(os.path.join(tmp, \"probes_sieve.xlsx\"))\n",
    "\n",
    "out_tmp = FOI[FOI[\"wanted\"] == True]\n",
    "output_df = pd.DataFrame()\n",
    "for gene in out_tmp.gene_name.unique():\n",
    "    pos_of_True = list(out_tmp[out_tmp.gene_name == gene][\"pos_on_seq\"])\n",
    "    best_pos = find_max_min_difference_fixed_length_subsequence(\n",
    "        pos_of_True,\n",
    "        length=3,\n",
    "        min_gap=40,\n",
    "        better_gap=80,\n",
    "        gene=gene,\n",
    "    )\n",
    "    out_subset = out_tmp[out_tmp.gene_name == gene]\n",
    "    out_subset = out_subset[out_subset[\"pos_on_seq\"].isin(best_pos)]\n",
    "    output_df = pd.concat([output_df, out_subset])\n",
    "\n",
    "# write the output to a xlsx file\n",
    "output_df.to_excel(os.path.join(output, \"probes_wanted.xlsx\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
